{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Projet numérique de Science des Données 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "__Binôme numéro 33 -- KATAEVSKII Mikhail et GIRARDET Grégoire__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dans ce projet, il s'agira d'étudier un jeu de données concernant des femmes diabétiques enceintes. Le diabète constitue un facteur de risque pour le bon déroulé de la grossesse. Pour chacune de ces femmes, nous disposons de 7 variables :\n",
    "* `Age` : l'âge en années\n",
    "* `Tension systolique` : la tension systolique en mmHg\n",
    "* `Tension diastolique` : la tension diastolique en mmHg\n",
    "* `Glycémie` : glycémie post-prandiale en mmol/L\n",
    "* `Température` : température en °C\n",
    "* `FC au repos` : fréquence cardiaque au repos\n",
    "* `Risque` : degré de risque obstétrique (0 : faible, 1 : moyen, 2 : élevé)\n",
    "\n",
    "\n",
    "Ce projet comporte trois partie :\n",
    "1. Une analyse exploratoire des données\n",
    "2. La construction d'un classifieur binaire permettant de séparer les femmes dont la grossesse est à risque de celles dont elle ne l'est pas\n",
    "3. La construction d'un classifieur multi-classe permettant de séparer les grossesses en trois classes : hautement à risque, moyennement à risque, faiblement à risque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "* Former un binôme et l'inscrire dans Moodle.\n",
    "* Renseigner le numéro de binôme et vos noms tout en haut de ce notebook à l'emplacement indiqué.\n",
    "* Déposer ce notebook complété **au plus tard le 10 juillet 2025, 23h59** sur Moodle.\n",
    "\n",
    "La présence aux séances dédiés au mini-projet (20/06 et 7/07) est **notée**. \n",
    "\n",
    "Les questions **1 à 14** peuvent être traitées dès la première séance. \n",
    "La question **15** peut être traitée après la PC4.\n",
    "Les questions **16 à 30** peuvent être traitées à partir de la PC5.\n",
    "\n",
    "Pour des raisons pédagogiques (voir la note à ce sujet), **l'usage d'assistants de code ou d'agents conversationnels tels que ChatGPT, Copilot, Claude, LeChat est prohibé. Leur utilisation sera sanctionnée.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Question 1 (1pt)\n",
    "\n",
    "Les données ont été récoltées dans une région défavorisée du monde, où les populations sont très pauvres et peuvent difficilement consulter. Quel peut être l'intérêt de déléguer à un algorithme la prédiction du risque obstétrique ? Quelles peuvent être les dérives (sociales, éthiques, économiques, psychologiques) d'une telle pratique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d57ef",
   "metadata": {},
   "source": [
    "__Réponse__ : L'utilisation d'un algorithme permettrait à un plus grand nombre de personnes d'estimer les risques obstétriques, surtout dans les zones dépourvues de médecins, ou encore dans des zones difficilement accessibles.\n",
    "\n",
    "Cependant, un tel algorithme peut ne pas être totalement fiable, et dans l'absence d'un médecin qualifié, les utilisateurs ne pourront pas vérifier les réponses données par cet algorithme. Les utilisateurs devront aussi effectuer les mesures nécessaires par eux-mêmes, ce qui diminue la précision de données fournies, et pourra conduire à des évaluations erronées.\n",
    "\n",
    "Les dérives d'utilisation de cet algorithme sont nombreuses. Tout d'abord, une fausse estimation pourrait mettre en danger une personne à forte risque dans le cas où ce risque serait sous-évalué. Au contraire, une personne dont le risque serait sur-évalue pourrait décider à avorter et ne pas avoir d'enfants dans le futur, alors qu'elle ne présente pas de risque élevé.\n",
    "L'utilisation massive d'un tel algorithme pourrait conduire à terme à une diminution du nombre de médecins qualifiés dans la région concernée (puisqu'il n'y aura *a priori* plus besoin de médecins pour effectuer cette tache) ce qui pourrait aggraver le problème.\n",
    "De plus, cela pourrait conduire à la diminution du budget alloué au traitement de femmes diabétiques enceintes.\n",
    "Sur le plan psychologique, la possibilité d'utiliser un algorithme découragerait les patients à consulter les médecins compétents, et pourrait même conduire à une perte de confiance vis à vis de la médecine lorsque les résultats données pas l'algorithme sont erronés. Ces personnes pourraient se tourner vers la médecine alternative, qui pourrait même nuire à leur santé.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Librairies usuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c12f7-a68e-465d-bf88-02407045b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme ()\n",
    "from sklearn import preprocessing, decomposition, neighbors, metrics, model_selection, linear_model, neural_network\n",
    "\n",
    "plt.rc('font', **{'size': 12}) # règle la taille de police globalement pour les plots (en pt)\n",
    "\n",
    "np.random.seed(19) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Nous allons pour l'instant travailler avec le jeu de données d'entraînement `data/donnees_entrainement.csv` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/donnees_entrainement.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Commençons par en extraire deux arrays, `X_train` et `y_train`, contenant d'une part les variables décrivant les observations et d'autre part leurs étiquettes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df_train.drop('Risque', axis=1))\n",
    "y_train = np.array(df_train['Risque'], dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# 1. Exploration de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Distributions des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Question 2 (1 pt)\n",
    "Pour chaque variable, affichez un histogramme de sa distribution dans chacune des trois classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette solution est adaptée de la PC 3\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "for (feat_idx, feat_name) in enumerate(df_train.columns[:-1]):\n",
    "    ax = fig.add_subplot(2, 3, (feat_idx+1))\n",
    "\n",
    "    h = ax.hist(df_train[df_train['Risque'] == 0][feat_name], bins=10,  \n",
    "                color='tab:green', edgecolor='none', alpha=1, label='Risque faible')\n",
    "    h = ax.hist(df_train[df_train['Risque'] == 1][feat_name], bins=10,  \n",
    "                color='tab:orange', edgecolor='none', alpha=0.7, label='Risque moyen')\n",
    "    h = ax.hist(df_train[df_train['Risque'] == 2][feat_name], bins=10,  \n",
    "            color='tab:red', edgecolor='none', alpha=0.7, label='Risque élevé')\n",
    "    \n",
    "    ax.set_title(feat_name)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Question 3 (1 pt)\n",
    "Les valeurs prises par ces variables sont-elles surprenantes ? Cohérentes avec le degré de risque ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "__Réponse__ : Les données sont plutôt cohérentes. On s'attend par exemple à ce que le risque augmente avec l'âge, la tension systolique / diastolique et avec le taux de glycémie, ce qui correspond aux données observées. On le voit particulièrement bien avec le taux de glycémie, puisque la majorité de personnes avec un taux supérieur à 10 mmol/L ont un risque élevé.\n",
    "\n",
    "Par contre, on pourrait aussi s'attendre à ce que le risque augmente avec la température ou la fréquence cardiaque, mais les données ne semblent pas confirmer cette hypothèse. La proportion de différentes catégories de risque reste à peu près uniforme pour les personnes qui présentent la température ou la fréquence cardiaque élevée. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Question 4 (1 pt)\n",
    "Pensez-vous qu'il va être facile/difficile de prédire le risque de grossesse à risque en utilisant ces 6 variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "__Réponse__ : Il semble assez facile de prédire le risque à l'aide de ces six variables, voire même en ignorant quelques unes qui ne semblent pas déterminantes. On voit par exemple des pics bien distinctes pour la tension diastolique en fonction de catégorie de risque ou encore la fait que le taux de glycémie élevé est systématiquement associé à risque élevé.\n",
    "\n",
    "Cependant, certaines variables ne permettent pas de distinguer les catégories de risque, par exemple la fréquence cardiaque (les 3 pics sont au même endroit). D'autres variables présentent une densité importante dans la même zone pour les trois catégorie (c'est le cas de la température, même si la température élevée augmente le risque, la plupart de valeurs sont inférieures à 37,5) ce qui rend la classification plus difficile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Réduction de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Indépendamment de votre réponse à la question précédente, nous allons procéder à deux tentatives de réduction de dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Question 5 (1 pt)\n",
    "Utilisez la décomposition en composantes principales de `X_train` pour visualiser les données en deux dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette solution est adaptée de la PC 4\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Standardisation des données\n",
    "std_scale = preprocessing.StandardScaler().fit (X_train)  # Standardisation des données\n",
    "X_train_scaled = std_scale.transform (X_train)\n",
    "# Projection sur deux composantes\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit (X_train_scaled)\n",
    "X_train_projected = pca.transform (X_train_scaled)\n",
    "# Affichage du résultat\n",
    "sns.scatterplot (x=X_train_projected[:, 0], y=X_train_projected[:, 1], hue=y_train)\n",
    "plt.xlabel (\"Composante 1\")\n",
    "plt.ylabel (\"Composante 2\")\n",
    "plt.title(\"Réduction de dimension avec 2 composantes principales\")\n",
    "plt.legend(title=\"Niveau de risque\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Question 6 (1 pt) \n",
    "Pensez-vous utile d'utiliser cette ACP pour réduire la dimension des données pour construire un prédicteur de risque de grossesse difficile ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7433edf2",
   "metadata": {},
   "source": [
    "__Réponse__ : On peut distinguer assez clairement les zones de risque élevé à partir de deux variables. Elles correspondent approximativement aux cas où la première composante est supérieure à 1 ou la deuxième composante est supérieure à 1. On peut aussi distinguer une zone de risque faible en bas à gauche. Par contre, on n'arrive pas à distinguer clairement les zones de risque faible et élevé.\n",
    "\n",
    "Si notre but est de séparer les cas de risque élevé du reste on peux se contenter de cette ACP. Sinon, il faut utiliser plus de composantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Question 7 (0,5 pt)\n",
    "Affichez la matrice de corrélation entre les variables (étiquette exclue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de corrélation deux à deux\n",
    "corr_matrix = df_train.drop('Risque', axis=1).corr()\n",
    "\n",
    "# Affichage heatmap\n",
    "sns.heatmap(corr_matrix, \n",
    "            vmin=-1, # borne inf des valeurs à afficher\n",
    "            vmax=1, # borne sup des valeurs à afficher\n",
    "            center= 0, # valeur médiane des valeurs à afficher,\n",
    "            cmap='PuOr', # colormap divergente de violet (PUrple) vers orange (ORange)\n",
    "           )\n",
    "\n",
    "# Titre\n",
    "plt.title(\"Corrélation entre les variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Question 8 (0,5 pt)\n",
    "\n",
    "Comment utiliser cette matrice de corrélation pour réduire la dimension des données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "__Réponse__ : On remarque que certaines variables sont forment corrélées, ce qui veut dire que l'on peut réduire la dimension sans risquer de perdre beaucoup d'information. On distingue à peu près 2 carrés indépendantes sur le graphe, donc on doit pouvoir se limiter à deux composantes principales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "# 2. Classification «à risque» vs «sans risque»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Nous allons maintenant transformer les étiquettes en étiquettes binaire, en regroupant les risques obstétriques moyens et élevés. Les étiquettes `1` et `2` seront regroupées en une seule étiquette `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copier le dataframe initial dans un nouveau dataframe \n",
    "df_train_risk_vs_norisk = df_train.copy()\n",
    "\n",
    "# Regrouper les étiquettes 1 et 2\n",
    "df_train_risk_vs_norisk['Risque'] = np.where(df_train['Risque']==2, 1, df_train['Risque'])\n",
    "\n",
    "# Extraction de l'array d'étiquettes\n",
    "y_train_risk_vs_norisk = np.array(df_train_risk_vs_norisk['Risque'], dtype='int')\n",
    "\n",
    "df_train_risk_vs_norisk.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Choix du critère d'évaluation\n",
    "Pour cette section, on pourra se référer à la section 8.7.1 du poly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Question 9 (0,25 pt)\n",
    "Quelle serait l'_accuracy_ (proportion d'observations correctement étiquetées) d'un modèle qui prédit que toutes les observations appartiennent à la classe majoritaire (c'est-à-dire la classe ayant le plus grand nombre d'observations dans les données) ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(df_train_risk_vs_norisk[df_train_risk_vs_norisk['Risque'] == 1])\n",
    "y = len(df_train_risk_vs_norisk)\n",
    "print(f\"L'accuracy est de {max(x, y - x) / y} si on étiquette tout comme faisant partie du groupe majoritaire.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Question 10 (0,25 pt) \n",
    "La __précision équilibrée__ (_balanced accuracy_) d'un classifieur binaire est donnée par :\n",
    "\n",
    "$$BA = \\frac12 \\left( \\frac{\\text{TP}}{\\text{TP}+\\text{FN}} +  \\frac{\\text{TN}}{\\text{TN}+\\text{FP}} \\right)$$\n",
    "\n",
    "Expliquez pourquoi ce critère d'évaluation est plus pertinent que l'accuracy pour sélectionner un classifieur optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "__Réponse__ : Cette grandeur est la moyenne du taux de vrais positifs et du taux de vrais négatifs. Pour la maximiser, il faut donc à la fois faire classifier correctement les positifs des négatifs. Contrairement à l'accuracy, cette grandeur est plus pertinente dans le cas où il y a très peu d'observation appartenant à une certaine classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Dans la suite du projet, nous utiliserons ce critère, implémenté dans la méthode [metrics.balanced_accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html) de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Plus proche voisin\n",
    "L'algorithme du plus proche voisin associe à une observation $\\vec{x}$ l’étiquette du point du jeu d’entraînement dont elle est la plus proche (par défaut, en distance euclidienne)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Question 11 (0,5 pt)\n",
    "En quoi consiste la phase d'entraînement d'un tel classifieur ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "__Réponse__ : La phase d’entraînement d'un tel modèle consiste simplement à mémoriser tous les points du jeu d’entraînement. C'est pendant la phase de prédiction qu'on va calculer le plus proche voisin et fournir la prédiction associée. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Question 12 (0,5 pt)\n",
    "Quelle précision équilibrée attendez-vous _sur le jeu d'entraînement_ d'un algorithme du plus proche voisin ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "__Réponse__ : On a vu sur le graphe avec les 2 composantes principales que la majorité de points se situent dans la zone centrale du graphe, où les cas à faible risque sont mélangés avec les cas à risque moyen. On s'attend à ce que le taux d'erreur dans cette zone soit particulièrement élevé. En ce qui concerne les zones à droite et en haut, ce sont essentiellement des zones à risque élevé, mais on y trouve un nombre faible de points.\n",
    "\n",
    "Il semble qu'il y a à peu près 1/3 des points dans les zones bien définies (donc avec une precision proche de 100%), et le reste dans des zones mixtes (on peut estimer la précision à 50%). On peut donc s'attendre à une précision finale proche de 66%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Question 13 (0,5 pt)\n",
    "Vérifiez votre réponse sur les données, en utilisant la classe [neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On separe les données d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_train_scaled, y_train_risk_vs_norisk, test_size=0.20, random_state=27)\n",
    "\n",
    "neigh = neighbors.KNeighborsClassifier()\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "print (f\"BA = {metrics.balanced_accuracy_score(y_test, neigh.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10f77d5",
   "metadata": {},
   "source": [
    "La précision est plus faible que celle intuitée. Cela provient probablement du fait que la précision dans les zones à risque élevé est inférieure à 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### Quesion 14 (0,5 pt)\n",
    "Pour cet algorithme, vaut-il mieux utiliser les données d'origine ou les données centrées-réduites ? Justifiez votre réponse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Il vaut mieux utiliser les données centrées-réduites afin de rapprocher les points qui possèdent des valeurs très grandes (ou très petites) les unes des autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "## K plus proches voisins\n",
    "L'algorithme des $K$ plus proche voisins associe à une observation $\\vec{x}$ l’étiquette qui est majoritaires parmi celle des $K$ points du jeu d’entraînement dont elle est la plus proche (par défaut, en distance euclidienne)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "### Question 15 (1,5 pt)\n",
    "Utilisez une recherche sur grille avec une validation croisée en 10 _folds_ (voir amphi 7 et PC5) pour déterminer une valeur optimale de $K$. \n",
    "\n",
    "* Justifiez votre choix de grille de valeurs.\n",
    "* Illustrez par un graphique approprié votre exploration de cette grille.\n",
    "* Commentez ce graphique.\n",
    "* Reportez la valeur optimale de l'hyperparamètre et la précision équilibrée correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5628b2b",
   "metadata": {},
   "source": [
    "Pour commencer, on peut tracer l'allure globale du graphe. Pour cela, on prendra 40 valeurs uniformément répartis sur toute la plage de valeurs possible ( donc allant de de 1 à $\\frac{9}{10} \\lvert y_{train} \\rvert$ ). Contrairement à la PC5, on n'utilisera pas une échelle logarithmique puisque la plage de valeurs possibles est assez petite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette solution est adaptée de la PC 5\n",
    "\n",
    "# Définir la grille de valeurs de l'hyperparamètre\n",
    "ks = np.linspace(1, len(y_train) / 10 * 9, 50, dtype=int)\n",
    "\n",
    "\n",
    "# Définir le modèle à évaluer\n",
    "neigh = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "grid = model_selection.GridSearchCV(neigh, {'n_neighbors': ks}, \n",
    "                                    cv=kf, # on utilise les folds déjà définis\n",
    "                                    scoring='balanced_accuracy'\n",
    "                                   )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid.fit(X_train_scaled, y_train_risk_vs_norisk)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "precision = grid.cv_results_['mean_test_score']\n",
    "std_error = grid.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE :\n",
    "plt.plot(grid.cv_results_['param_n_neighbors'], precision, \n",
    "             label=\"précision équilibrée\", color='tab:blue')\n",
    "plt.plot(grid.cv_results_['param_n_neighbors'], precision + std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "plt.plot(grid.cv_results_['param_n_neighbors'], precision - std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(ks, (precision + std_error), (precision - std_error), \n",
    "                 color='tab:blue',\n",
    "                 alpha=0.2, # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"précision équilibrée +/- un écart-type\")\n",
    "plt.xlim([ks[0], ks[-1]])\n",
    "plt.title(\"Recherche sur grille (k)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6719988",
   "metadata": {},
   "source": [
    "On voit que la précision est maximale pour les faibles valeurs de k. Au contraire, pour les valeurs très grandes, cette précision est constante et vaut 1/2 (parce que dans ce cas là, on renvoie la valeur la plus fréquente dans tout le jeu de données). De manière générale, on voit que la précision diminue lorsque k augmente. Cela est probablement due au fait qu'en augmentant k on diminue le nombre de différentes zones de risque distinctes, tout en augmentant la tailles de celles qui restent (car on prend en compte un plus grand nombre de voisins) ce qui diminue précision.\n",
    "\n",
    "On peut maintenant se concentrer la partie gauche de ca graphe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8efdec",
   "metadata": {},
   "source": [
    "Puisque le nombre de valeurs est assez faible, on peut calculer toutes les valeurs possibles de k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac41f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(1, 51, 1)\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "\n",
    "grid = model_selection.GridSearchCV(neigh, {'n_neighbors': ks}, \n",
    "                                    cv=kf, # on utilise les folds déjà définis\n",
    "                                    scoring='balanced_accuracy'\n",
    "                                   )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid.fit(X_train_projected, y_train_risk_vs_norisk)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "precision = grid.cv_results_['mean_test_score']\n",
    "std_error = grid.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE :\n",
    "plt.plot(grid.cv_results_['param_n_neighbors'], precision, \n",
    "             label=\"précision équilibrée\", color='tab:blue')\n",
    "plt.plot(grid.cv_results_['param_n_neighbors'], precision + std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "plt.plot(grid.cv_results_['param_n_neighbors'], precision - std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(ks, (precision + std_error), (precision - std_error), \n",
    "                 color='tab:blue',\n",
    "                 alpha=0.2, # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"précision équilibrée +/- un écart-type\")\n",
    "plt.xlim([ks[0], ks[-1]])\n",
    "plt.title(\"Recherche sur grille (k)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La meilleure valeur de k est {grid.best_params_['n_neighbors']} avec la précision équilibrée de {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## Régression logistique\n",
    "Le pendant pour la classification binaire de la régression linéaire (amphi 7 et PC 5) est la __régression logistique__ (PC 6). Dans scikit-learn, elle est implémentée par la classe [linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### Question 16 (1 pt) \n",
    "Utilisez une recherche sur grille avec une validation croisée en 10 _folds_ pour déterminer une valeur optimale du coefficient de régularisation d'une régression logistique. \n",
    "\n",
    "* Justifiez votre choix de type de régularisation et de grille de valeurs. \n",
    "* Illustrez par un graphique approprié votre exploration de cette grille. \n",
    "* Commentez ce graphique.\n",
    "* Reportez la valeur optimale de l'hyperparamètre et la précision équilibrée correspondante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b65e8",
   "metadata": {},
   "source": [
    "Comme on l'a vu sur les graphes au début du sujet, plusieurs paramètres ne permettent pas de distinguer clairement les différents niveaux de risque. On préférera donc une régularisation de type \"l1\" afin d'annuler ces coefficients peu utiles.\n",
    "\n",
    "On commence de nouveau avec avec un graphique assez grand pour identifier les plateaux. Une fois qu'on a identifié la zone qui nous intéresse, on trace uniquement cette zone là. Ici, on travaille de nouveau en logarithmique puisque la plage de valeurs qui présentent des variations est assez grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette solution est adaptée de la PC 5\n",
    "\n",
    "# Ce calcul peut prendre plus de 30 secondes à se terminer...\n",
    "\n",
    "# Définir la grille de valeurs de l'hyperparamètre\n",
    "cs = np.logspace(-2, 3, 20)\n",
    "\n",
    "\n",
    "# Définir le modèle à évaluer\n",
    "model = linear_model.LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=10000)\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "grid = model_selection.GridSearchCV(model, {'C': cs}, \n",
    "                                    cv=kf, # on utilise les folds déjà définis\n",
    "                                    scoring='balanced_accuracy'\n",
    "                                   )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid.fit(X_train_scaled, y_train_risk_vs_norisk)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "precision = grid.cv_results_['mean_test_score']\n",
    "std_error = grid.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE :\n",
    "plt.semilogx(grid.cv_results_['param_C'], precision, \n",
    "             label=\"précision équilibrée\", color='tab:blue')\n",
    "plt.semilogx(grid.cv_results_['param_C'], precision + std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "plt.semilogx(grid.cv_results_['param_C'], precision - std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(cs, (precision + std_error), (precision - std_error), \n",
    "                 color='tab:blue',\n",
    "                 alpha=0.2, # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"précision équilibrée +/- un écart-type\")\n",
    "plt.xlim([cs[0], cs[-1]])\n",
    "plt.title(\"Recherche sur grille (C)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c47ae",
   "metadata": {},
   "source": [
    "On observe un plateau à gauche de ce graphique, ce qui correspond au phénomène de sous-apprentissage, car on optimise la fonction sans tenir compte de données.\n",
    "\n",
    "Cependant, de manière assez étonnante, on trouve un autre plateau avec une précision égale à 1 à droite du tableau. Il semble donc que le phénomène de surapprentissage n'est pas présent ici. Cela est peut-être du au nombre faible de paramètres dans notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7859fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La meilleure valeur de C est {grid.best_params_['C']} avec la précision équilibrée de {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## Algorithme non-linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Question 17 (2pt)\n",
    "Choisissez maintenant un algorithme permettant d'apprendre un modèle non-linéaire parmi ceux du chapitre 9 :\n",
    "* arbre de décision : [tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "* forêt aléatoire : [ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* machine à vecteur de support à noyau : [svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "* perceptron multi-couche : [neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "\n",
    "Utilisez encore une fois une recherche sur grille avec une validation croisée en 10 _folds_ pour sélectionner le(s) hyperparamètre(s) le(s) plus pertinent(s).\n",
    "\n",
    "* Justifiez votre choix d'hyperparamètre(s) à optimiser.\n",
    "* Justifiez votre choix de grille de valeurs pour ces ou cet hyperparèmtre(s).\n",
    "* Illustrez par un graphique approprié votre exploration de cette grille.\n",
    "* Commentez ce graphique.\n",
    "* Reportez la ou les valeur(s) optimale(s) d'hyperparamètre(s) et la précision équilibrée correspondante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70258084",
   "metadata": {},
   "source": [
    "On va utiliser le perceptron multi-couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette solution est adaptée de la PC 5\n",
    "\n",
    "# Ce calcul peut prendre plus de 30 secondes à se terminer...\n",
    "\n",
    "# Définir la grille de valeurs de l'hyperparamètre C\n",
    "layers = np.arange(1, 21, 2)\n",
    "\n",
    "\n",
    "# Définir le modèle à évaluer\n",
    "model = neural_network.MLPClassifier(max_iter=10000)\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "grid = model_selection.GridSearchCV(model, {'hidden_layer_sizes': layers}, \n",
    "                                    cv=kf, # on utilise les folds déjà définis\n",
    "                                    scoring='balanced_accuracy'\n",
    "                                   )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid.fit(X_train_scaled, y_train_risk_vs_norisk)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "precision = grid.cv_results_['mean_test_score']\n",
    "std_error = grid.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE :\n",
    "plt.plot(grid.cv_results_['param_hidden_layer_sizes'], precision, \n",
    "             label=\"RMSE\", color='tab:blue')\n",
    "plt.plot(grid.cv_results_['param_hidden_layer_sizes'], precision + std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "plt.plot(grid.cv_results_['param_hidden_layer_sizes'], precision - std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(layers, (precision + std_error), (precision - std_error), \n",
    "                 color='tab:blue',\n",
    "                 alpha=0.2, # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Nombre de neurons dans la couche\")\n",
    "plt.ylabel(\"précision équilibrée +/- un écart-type\")\n",
    "plt.xlim([layers[0], layers[-1]])\n",
    "plt.title(\"Recherche sur grille (C)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## Classification après réduction de dimension\n",
    "\n",
    "Nous allons maintenant évaluer l'impact d'une réduction de dimension sur la qualité de l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "### Question 18 (0,25 pt)\n",
    "Quel algorithme (k plus proches voisins ; régression logistique ; algorithme non-linéaire de la question 16) vous a permis d'obtenir la meilleure performance ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "### Quesion 19 (0,25 pt)\n",
    "Utilisez le travail des questions 4 à 7 pour créer une nouvelle matrice représentant les données dans moins de dimensions qu'originellement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### Question 20 (0,25 pt)\n",
    "Utilisez encore une fois une recherche sur grille pour optimiser les performances de cet algorithme, mais entrainé sur cette nouvelle matrice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "### Question 21 (0,25 pt)\n",
    "La réduction de dimension a-t-elle été utile ? Commentez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "## Classifieur final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "### Question 22 (0,25 pt)\n",
    "Au vu des performances observées jusqu'à présent, quel est l'algorithme d'apprentissage, son ou ses valeurs d'hyperparamètres, la transformation des données qui permettent d'obtenir la meilleure performance ? \n",
    "\n",
    "Utilisez cet algorithme pour entraîner un modèle de classification final `final_binary_classifier` sur l'ensemble du jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### Question 23 (0,25 pt)\n",
    "\n",
    "Chargez les données du jeu de test `data/donnees_reservees.csv`. Combinez les étiquettes 1 et 2 en une seule classe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### Question 24 (0,25 pt)\n",
    "\n",
    "Utilisez `final_binary_classifier` pour prédire les étiquettes des observations de ce jeu de données. (N'oubliez pas d'appliquer d'éventuelles transformation des données.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "### Question 25 (0,5 pt)\n",
    "Comparez la précision équilibrée sur le jeu de test à celle obtenue en validation croisée lors de la sélection de modèle. Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "### Question 26 (0,25 pt)\n",
    "Utilisez [metrics.ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html) pour afficher la matrice de confusion de ces prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "### Question 27 (0,5 pt)\n",
    "Commentez cette matrice de précision.\n",
    "\n",
    "Considéreriez vous possible d'utilise ce classifieur pour décider, sur la base de ces quelques mesures faciles à obtenir en autonomie, quelles femmes référer pour un suivi médical attentif de leur grossesse ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "# 3. Classification multi-classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "### Question 28 (0,5 pt)\n",
    "Parmi les algorithmes d'apprentissage supervisé que vous avez utilisé dans la section 2, le(s)quel(s) se prête(nt) directement à entraîner un classifieur multiclasse ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Question 29 (1,5 pt)\n",
    "Choisissez un des algorithmes mentionnés à la question précédente et entraînez-le sur le problème de classification multi-classe consistant à prédire le niveau (0, 1 ou 2) de risque obstétrique. Optimisez le ou les hyperparamètre(s) le(s) plus pertinent(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "### Question 30 (1pt)\n",
    "Utilisez cet algorithme pour entraîner un modèle multi-classe final sur l'ensemble des données d'entraînement. Évaluez ce modèle sur les données de test. Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
